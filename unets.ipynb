{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Successfully installed required packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q --upgrade keras keras-cv tensorflow tensorflow_datasets setuptools scikit-learn segmentation-models matplotlib opencv-python seaborn keras_tuner pandas\n",
        "print(\"Successfully installed required packages.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle\n",
        "# !kaggle datasets download -d tawsifurrahman/tuberculosis-tb-chest-xray-dataset\n",
        "!kaggle datasets download -d nikhilpandey360/chest-xray-masks-and-labels\n",
        "!unzip chest-xray-masks-and-labels.zip\n",
        "# !unzip tuberculosis-tb-chest-xray-dataset.zip\n",
        "# !rm -rf data\n",
        "!mv Lung\\ Segmentation segmentation_data\n",
        "!rm -rf ./segmentation_data/ClinicalReadings\n",
        "!rm -rf ./data\n",
        "!rm ./segmentation_data/NLM-ChinaCXRSet-ReadMe.docx\n",
        "!rm ./segmentation_data/NLM-MontgomeryCXRSet-ReadMe.pdf\n",
        "!mv ./segmentation_data/CXR_png ./segmentation_data/images\n",
        "# !mv TB_Chest_Radiography_Database data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-21 09:31:33.307957: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-08-21 09:31:33.318631: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-21 09:31:33.331212: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-21 09:31:33.334982: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-21 09:31:33.344347: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "import segmentation_models as sm\n",
        "import keras\n",
        "import keras_tuner\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = \"./segmentation_data\"\n",
        "image_dir = os.path.join(DATA_DIR, \"images\")\n",
        "mask_dir = os.path.join(DATA_DIR, \"masks\")\n",
        "\n",
        "masks = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n",
        "for mask in masks:\n",
        "    if mask.endswith(\"_mask.png\"):\n",
        "        os.rename(os.path.join(mask_dir, mask), os.path.join(mask_dir, mask.replace(\"_mask\", \"\")))\n",
        "\n",
        "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "for img in images:\n",
        "    if os.path.isfile(os.path.join(mask_dir, img)):\n",
        "        continue\n",
        "    os.remove(os.path.join(image_dir, img))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "masks = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
        "masks = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n",
        "\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(images, masks, test_size=0.1)\n",
        "\n",
        "if os.path.exists(os.path.join(DATA_DIR, \"train\")):\n",
        "    print(\"Removing existing train dataset...\")\n",
        "    shutil.rmtree(os.path.join(DATA_DIR, \"train\"))\n",
        "\n",
        "if os.path.exists(os.path.join(DATA_DIR, \"val\")):\n",
        "    print(\"Removing existing validation dataset...\")\n",
        "    shutil.rmtree(os.path.join(DATA_DIR, \"val\"))\n",
        "\n",
        "train_image_dir = os.path.join(DATA_DIR, \"train\", \"images\")\n",
        "val_image_dir = os.path.join(DATA_DIR, \"val\", \"images\")\n",
        "train_mask_dir = os.path.join(DATA_DIR, \"train\", \"masks\")\n",
        "val_mask_dir = os.path.join(DATA_DIR, \"val\", \"masks\")\n",
        "\n",
        "os.makedirs(train_image_dir, exist_ok=True)\n",
        "os.makedirs(val_image_dir, exist_ok=True)\n",
        "os.makedirs(train_mask_dir, exist_ok=True)\n",
        "os.makedirs(val_mask_dir, exist_ok=True)\n",
        "\n",
        "def copy_files(file_list, src_dir, dst_dir):\n",
        "    for file in file_list:\n",
        "        shutil.copy(os.path.join(src_dir, file), os.path.join(dst_dir, file))\n",
        "\n",
        "print(\"Copying train images...\")\n",
        "copy_files(train_images, image_dir, train_image_dir)\n",
        "print(\"Copying validation images...\")\n",
        "copy_files(val_images, image_dir, val_image_dir)\n",
        "print(\"Copying train masks...\")\n",
        "copy_files(train_masks, mask_dir, train_mask_dir)\n",
        "print(\"Copying validation masks...\")\n",
        "copy_files(val_masks, mask_dir, val_mask_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/tutorials/images/segmentation\n",
        "class Augment(tf.keras.layers.Layer):\n",
        "    def __init__(self, seed=42):\n",
        "        super().__init__()\n",
        "\n",
        "        # both use the same seed, so they'll make the same random changes.\n",
        "        self.augment_inputs = keras.Sequential([\n",
        "            keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=seed),\n",
        "            keras.layers.RandomBrightness(factor=0.2, seed=seed),\n",
        "            keras.layers.RandomRotation(factor=0.2, seed=seed)\n",
        "        ])\n",
        "        self.augment_labels = keras.Sequential([\n",
        "            keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=seed),\n",
        "            keras.layers.RandomRotation(factor=0.2, seed=seed)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs, labels):\n",
        "        inputs = self.augment_inputs(inputs)\n",
        "        labels = self.augment_labels(labels)\n",
        "\n",
        "        labels = labels / 255\n",
        "        return inputs, labels\n",
        "  \n",
        "def augment_validation(inputs, labels):\n",
        "    return inputs, labels / 255\n",
        "\n",
        "def get_data(batch_size):\n",
        "    train_images, validation_images = keras.utils.image_dataset_from_directory(\n",
        "        \"segmentation_data/train/images\",\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        image_size=(256, 256),\n",
        "        shuffle=False,\n",
        "        validation_split=0.1,\n",
        "        subset='both'\n",
        "    )\n",
        "\n",
        "    train_masks, validation_masks = keras.utils.image_dataset_from_directory(\n",
        "        \"segmentation_data/train/masks\",\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        image_size=(256, 256),\n",
        "        color_mode='grayscale',\n",
        "        shuffle=False,\n",
        "        validation_split=0.1,\n",
        "        subset='both'\n",
        "    )\n",
        "\n",
        "    training_dataset = tf.data.Dataset.zip(train_images, train_masks)\n",
        "    validation_dataset = tf.data.Dataset.zip(validation_images, validation_masks)\n",
        "\n",
        "    training_dataset = training_dataset.map(Augment()).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    validation_dataset = validation_dataset.map(augment_validation).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return training_dataset, validation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resnet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "BACKBONE = 'resnet34'\n",
        "def build_resnet_model(hp):\n",
        "    loss_idx = hp.Choice('loss_idx', values=[0, 1])\n",
        "    losses = [keras.losses.binary_crossentropy, sm.losses.dice_loss]\n",
        "    loss = losses[loss_idx]\n",
        "\n",
        "    optimizer_idx = hp.Choice('optimizer_idx', values=[0, 1])\n",
        "    optimizers = [keras.optimizers.Adam(), keras.optimizers.SGD()]\n",
        "    optimizer = optimizers[optimizer_idx]\n",
        "\n",
        "    model = sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=['accuracy', sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 4 Complete [00h 12m 00s]\n",
            "val_loss: 0.20852604508399963\n",
            "\n",
            "Best val_loss So Far: 0.17512701451778412\n",
            "Total elapsed time: 00h 32m 36s\n"
          ]
        }
      ],
      "source": [
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "def process_dataset(images, labels):\n",
        "    return preprocess_input(images), labels\n",
        "\n",
        "for batch_size in [4, 8, 16]:\n",
        "    project_name= 'resnet34-%d' % batch_size\n",
        "\n",
        "    training_dataset, validation_dataset = get_data(batch_size)\n",
        "    training_dataset = training_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    validation_dataset = validation_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    tuner = keras_tuner.GridSearch(\n",
        "        objective='val_loss',\n",
        "        hypermodel=build_resnet_model,\n",
        "        project_name=project_name\n",
        "    )\n",
        "\n",
        "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir='tensorboard/%s' % (project_name))\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, start_from_epoch=10)\n",
        "    reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(patience=5, cooldown=5)\n",
        "\n",
        "    tuner.search(\n",
        "        training_dataset,\n",
        "        batch_size=batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=validation_dataset,\n",
        "        callbacks=[tensorboard_cb, early_stopping_cb, reduce_lr_cb]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inceptionv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "BACKBONE = 'inceptionv3'\n",
        "def build_inceptionv3_model(hp):\n",
        "    loss_idx = hp.Choice('loss_idx', values=[0, 1])\n",
        "    losses = [keras.losses.binary_crossentropy, sm.losses.dice_loss]\n",
        "    loss = losses[loss_idx]\n",
        "\n",
        "    optimizer_idx = hp.Choice('optimizer_idx', values=[0, 1])\n",
        "    optimizers = [keras.optimizers.Adam(), keras.optimizers.SGD()]\n",
        "    optimizer = optimizers[optimizer_idx]\n",
        "\n",
        "    model = sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=['accuracy', sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 4 Complete [00h 11m 53s]\n",
            "val_loss: 0.2067612260580063\n",
            "\n",
            "Best val_loss So Far: 0.17479930818080902\n",
            "Total elapsed time: 00h 33m 12s\n"
          ]
        }
      ],
      "source": [
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "def process_dataset(images, labels):\n",
        "    return preprocess_input(images), labels\n",
        "\n",
        "for batch_size in [4, 8, 16]:\n",
        "    project_name = 'inceptionv3-%d' % batch_size\n",
        "\n",
        "    training_dataset, validation_dataset = get_data(batch_size)\n",
        "    training_dataset = training_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    validation_dataset = validation_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    tuner = keras_tuner.GridSearch(\n",
        "        objective='val_loss',\n",
        "        hypermodel=build_inceptionv3_model,\n",
        "        project_name=project_name\n",
        "    )\n",
        "\n",
        "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir='tensorboard/%s' % (project_name))\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, start_from_epoch=10)\n",
        "    reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(patience=5, cooldown=5)\n",
        "\n",
        "    tuner.search(\n",
        "        training_dataset,\n",
        "        batch_size=batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=validation_dataset,\n",
        "        callbacks=[tensorboard_cb, early_stopping_cb, reduce_lr_cb]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = keras.layers.Conv2D(num_filters, 3, padding='same')(inputs)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(num_filters, 3, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = keras.layers.MaxPool2D((2, 2))(x)\n",
        "\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip, num_filters):\n",
        "    x = keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
        "    x = keras.layers.Concatenate()([x, skip])\n",
        "    x = conv_block(x, num_filters)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape=(256, 256, 3)):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 64)\n",
        "    s3, p3 = encoder_block(p2, 64)\n",
        "    s4, p4 = encoder_block(p3, 64)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 512)\n",
        "    d3 = decoder_block(d2, s2, 512)\n",
        "    d4 = decoder_block(d3, s1, 512)\n",
        "\n",
        "    outputs = keras.layers.Conv2D(1, 1, padding='same', activation='sigmoid')(d4)\n",
        "    return keras.Model(inputs, outputs, name='U-Net')\n",
        "\n",
        "def build_original_model(hp):\n",
        "    loss_idx = hp.Choice('loss_idx', values=[0, 1, 2, 3])\n",
        "    losses = [sm.losses.bce_jaccard_loss, sm.losses.jaccard_loss, sm.losses.bce_dice_loss, sm.losses.dice_loss]\n",
        "    loss = losses[loss_idx]\n",
        "\n",
        "    optimizer_idx = hp.Choice('optimizer_idx', values=[0])\n",
        "    optimizers = [keras.optimizers.Adam()]\n",
        "    optimizer = optimizers[optimizer_idx]\n",
        "\n",
        "    model = build_unet()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=['accuracy', sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 2 Complete [00h 19m 59s]\n",
            "val_loss: 0.30447280406951904\n",
            "\n",
            "Best val_loss So Far: 0.30447280406951904\n",
            "Total elapsed time: 00h 35m 02s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2                 |1                 |loss_idx\n",
            "0                 |0                 |optimizer_idx\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 408ms/step - accuracy: 0.7451 - f1-score: 0.4798 - iou_score: 0.3242 - loss: 1.0716 - val_accuracy: 0.2983 - val_f1-score: 0.2961 - val_iou_score: 0.1742 - val_loss: 2.3309 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 342ms/step - accuracy: 0.8385 - f1-score: 0.6208 - iou_score: 0.4523 - loss: 0.7524 - val_accuracy: 0.3074 - val_f1-score: 0.4451 - val_iou_score: 0.2869 - val_loss: 2.6043 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 345ms/step - accuracy: 0.8492 - f1-score: 0.6407 - iou_score: 0.4741 - loss: 0.7089 - val_accuracy: 0.7620 - val_f1-score: 0.6625 - val_iou_score: 0.4964 - val_loss: 0.9062 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 348ms/step - accuracy: 0.8614 - f1-score: 0.6740 - iou_score: 0.5100 - loss: 0.6546 - val_accuracy: 0.8333 - val_f1-score: 0.7284 - val_iou_score: 0.5750 - val_loss: 0.7339 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 348ms/step - accuracy: 0.8633 - f1-score: 0.6810 - iou_score: 0.5181 - loss: 0.6384 - val_accuracy: 0.8721 - val_f1-score: 0.7549 - val_iou_score: 0.6086 - val_loss: 0.5966 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 348ms/step - accuracy: 0.8638 - f1-score: 0.6807 - iou_score: 0.5176 - loss: 0.6370 - val_accuracy: 0.8810 - val_f1-score: 0.7615 - val_iou_score: 0.6174 - val_loss: 0.5618 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 344ms/step - accuracy: 0.8691 - f1-score: 0.6926 - iou_score: 0.5315 - loss: 0.6122 - val_accuracy: 0.8896 - val_f1-score: 0.7330 - val_iou_score: 0.5809 - val_loss: 0.5662 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 346ms/step - accuracy: 0.8682 - f1-score: 0.6889 - iou_score: 0.5270 - loss: 0.6165 - val_accuracy: 0.8778 - val_f1-score: 0.7326 - val_iou_score: 0.5797 - val_loss: 0.5683 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 345ms/step - accuracy: 0.8692 - f1-score: 0.6907 - iou_score: 0.5294 - loss: 0.6124 - val_accuracy: 0.8711 - val_f1-score: 0.7118 - val_iou_score: 0.5537 - val_loss: 0.5991 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m 56/143\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 322ms/step - accuracy: 0.8702 - f1-score: 0.6814 - iou_score: 0.5188 - loss: 0.6152"
          ]
        }
      ],
      "source": [
        "def preprocess_input(images):\n",
        "    return images / 255\n",
        "\n",
        "def process_dataset(images, labels):\n",
        "    return preprocess_input(images), labels\n",
        "\n",
        "for batch_size in [4, 8, 16]:\n",
        "    project_name = 'original-%d' % batch_size\n",
        "\n",
        "    training_dataset, validation_dataset = get_data(batch_size)\n",
        "    training_dataset = training_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    validation_dataset = validation_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    tuner = keras_tuner.GridSearch(\n",
        "        objective='val_loss',\n",
        "        hypermodel=build_original_model,\n",
        "        project_name=project_name\n",
        "    )\n",
        "\n",
        "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir='tensorboard/%s' % (project_name))\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, start_from_epoch=10)\n",
        "    reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(patience=5, cooldown=5)\n",
        "\n",
        "    tuner.search(\n",
        "        training_dataset,\n",
        "        batch_size=batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=validation_dataset,\n",
        "        callbacks=[tensorboard_cb, early_stopping_cb, reduce_lr_cb]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EfficientNetB5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BACKBONE = 'efficientnetb5'\n",
        "def build_efficientnet_model(hp):\n",
        "    loss_idx = hp.Choice('loss_idx', values=[0, 1])\n",
        "    losses = [keras.losses.binary_crossentropy, sm.losses.dice_loss]\n",
        "    loss = losses[loss_idx]\n",
        "\n",
        "    optimizer_idx = hp.Choice('optimizer_idx', values=[0, 1])\n",
        "    optimizers = [keras.optimizers.Adam(), keras.optimizers.SGD()]\n",
        "    optimizer = optimizers[optimizer_idx]\n",
        "\n",
        "    model = sm.Unet(BACKBONE, encoder_weights='imagenet', encoder_freeze=True)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=['accuracy', sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "def process_dataset(images, labels):\n",
        "    return preprocess_input(images), labels\n",
        "\n",
        "for batch_size in [4, 8, 16]:\n",
        "    project_name = 'efficientnetb5-%d' % batch_size\n",
        "\n",
        "    training_dataset, validation_dataset = get_data(batch_size)\n",
        "    training_dataset = training_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    validation_dataset = validation_dataset.map(process_dataset).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    tuner = keras_tuner.GridSearch(\n",
        "        objective='val_loss',\n",
        "        hypermodel=build_efficientnet_model,\n",
        "        project_name=project_name\n",
        "    )\n",
        "\n",
        "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir='tensorboard/%s' % (project_name))\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, start_from_epoch=10)\n",
        "    reduce_lr_cb = keras.callbacks.ReduceLROnPlateau(patience=5, cooldown=5)\n",
        "\n",
        "    tuner.search(\n",
        "        training_dataset,\n",
        "        batch_size=batch_size,\n",
        "        epochs=50,\n",
        "        validation_data=validation_dataset,\n",
        "        callbacks=[tensorboard_cb, early_stopping_cb, reduce_lr_cb]\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
