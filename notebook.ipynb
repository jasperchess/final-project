{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab9973b-fe33-496b-937d-085a73a09293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed required packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade keras tensorflow setuptools scikit-learn segmentation-models matplotlib opencv-python seaborn keras_tuner\n",
    "print(\"Successfully installed required packages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633fa93a-6406-4cc5-8494-bfe33664a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c614c-ab8b-4f01-ba0a-2243c3b19a6d",
   "metadata": {},
   "source": [
    "### Run the following code in a terminal\n",
    "\n",
    "```bash\n",
    "pip install kaggle\n",
    "kaggle datasets download -d tawsifurrahman/tuberculosis-tb-chest-xray-dataset\n",
    "kaggle datasets download -d nikhilpandey360/chest-xray-masks-and-labels\n",
    "unzip chest-xray-masks-and-labels.zip\n",
    "unzip tuberculosis-tb-chest-xray-dataset.zip\n",
    "rm -rf data\n",
    "mv Lung\\ Segmentation segmentation_data\n",
    "cd segmentation_data\n",
    "rm -rf ClinicalReadings\n",
    "rm NLM-ChinaCXRSet-ReadMe.docx\n",
    "rm NLM-MontgomeryCXRSet-ReadMe.pdf\n",
    "mv CXR_png images\n",
    "\n",
    "cd ..\n",
    "mv TB_Chest_Radiography_Database data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c75473-d094-4a41-af64-860546545282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing dataset\n",
      "Copying train normal set...\n",
      "Copying test normal set...\n",
      "Copying train normal set...\n",
      "Copying test normal set...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_dir = './data/split'\n",
    "\n",
    "def split_dataset(base_split_dir='./data/split', normal_dir='./data/Normal', tb_dir='./data/Tuberculosis'):\n",
    "    train_split = 'train'\n",
    "    test_split = 'test'\n",
    "    splits = [train_split, test_split]\n",
    "    normal_class = 'normal'\n",
    "    tb_class = 'tuberculosis'\n",
    "    classes = [normal_class, tb_class]\n",
    "\n",
    "    normal_files = [f for f in os.listdir(normal_dir) if os.path.isfile(os.path.join(normal_dir, f))]\n",
    "    tb_files = [f for f in os.listdir(tb_dir) if os.path.isfile(os.path.join(tb_dir, f))]\n",
    "\n",
    "    if os.path.exists(base_split_dir):\n",
    "        print(\"Removing existing dataset\")\n",
    "        # If the split directory exists, remove it and so it can be regenerated\n",
    "        shutil.rmtree(base_split_dir)\n",
    "\n",
    "    # Split the data into training, test sets\n",
    "    # The validation set will be created from the training set at a later stage\n",
    "    train_normal, test_normal = train_test_split(normal_files, test_size=0.1)\n",
    "    train_tb, test_tb = train_test_split(tb_files, test_size=0.1)\n",
    "\n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(base_split_dir, split, cls), exist_ok=True)\n",
    "\n",
    "    # Function to copy files to their respective directories\n",
    "    def copy_files(file_list, dst_dir):\n",
    "        for file in file_list:\n",
    "            src_dir = normal_dir if file in normal_files else tb_dir\n",
    "            shutil.copy(os.path.join(src_dir, file), os.path.join(dst_dir, file))\n",
    "\n",
    "    print(\"Copying train normal set...\")\n",
    "    copy_files(train_normal, os.path.join(base_split_dir, train_split, normal_class))\n",
    "    print(\"Copying test normal set...\")\n",
    "    copy_files(test_normal, os.path.join(base_split_dir, test_split, normal_class))\n",
    "\n",
    "    print(\"Copying train normal set...\")\n",
    "    copy_files(train_tb, os.path.join(base_split_dir, train_split, tb_class))\n",
    "    print(\"Copying test normal set...\")\n",
    "    copy_files(test_tb, os.path.join(base_split_dir, test_split, tb_class))\n",
    "\n",
    "split_dataset(base_split_dir=split_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "677f298f-a074-4bdc-a5c5-ab201dc78a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 10:39:27.905594: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 10:39:27.923912: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 10:39:27.929612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-21 10:39:27.943381: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 10:39:30.327562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3780 files belonging to 2 classes.\n",
      "Using 3402 files for training.\n",
      "Using 378 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721558381.232162   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.239185   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.242916   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.248565   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.251849   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.254932   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.663298   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.665312   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721558388.666981   13823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 10:39:48.668395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 420 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "training_data = keras.utils.image_dataset_from_directory(\n",
    "    split_dir + \"/train\",\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset='both'\n",
    ")\n",
    "train_dataset, validation_dataset = training_data\n",
    "\n",
    "test = keras.utils.image_dataset_from_directory(\n",
    "    split_dir + \"/test\",\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06730754-b2ad-435c-b4d2-f35af92f7dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721558392.900708   16573 service.cc:146] XLA service 0x7f38f400b2f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721558392.900745   16573 service.cc:154]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-07-21 10:39:52.964425: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 10:39:53.821483: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  9/107\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7409 - loss: 13.5881 - precision: 0.2632 - recall: 0.2878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721558413.705348   16573 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 93ms/step - accuracy: 0.8147 - loss: 2.7348 - precision: 0.2527 - recall: 0.0446 - val_accuracy: 0.8492 - val_loss: 0.6588 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8310 - loss: 0.6533 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.6282 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8307 - loss: 0.6255 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.6012 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8280 - loss: 0.6016 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.5771 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8354 - loss: 0.5774 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.5561 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8324 - loss: 0.5596 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.5376 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8313 - loss: 0.5439 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.5218 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8272 - loss: 0.5323 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.5077 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8307 - loss: 0.5180 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.4956 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8303 - loss: 0.5080 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.8492 - val_loss: 0.4852 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 0.8425 - loss: 0.4908 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n"
     ]
    }
   ],
   "source": [
    "no_weighting_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(shape=(256, 256, 3)),\n",
    "    keras.layers.Conv2D(16, (7, 7), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "no_weighting_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "no_weighting_history = no_weighting_model.fit(train_dataset, epochs=10, validation_data=validation_dataset)\n",
    "\n",
    "no_weighting_results = no_weighting_model.evaluate(test)\n",
    "no_weighting_predictions = no_weighting_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf399bb8-e424-4d3b-8049-b104637cb536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.4735 - loss: 29.7301 - precision: 0.1574 - recall: 0.4663 - val_accuracy: 0.8492 - val_loss: 0.6919 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5684 - loss: 0.2332 - precision: 0.1304 - recall: 0.3960 - val_accuracy: 0.8492 - val_loss: 0.6930 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.6055 - loss: 0.2303 - precision: 0.1236 - recall: 0.3380 - val_accuracy: 0.1508 - val_loss: 0.6935 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1691 - loss: 0.2324 - precision: 0.1691 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6944 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1676 - loss: 0.2316 - precision: 0.1676 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6948 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1731 - loss: 0.2346 - precision: 0.1731 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6963 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1715 - loss: 0.2337 - precision: 0.1715 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6955 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1703 - loss: 0.2331 - precision: 0.1703 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6951 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1708 - loss: 0.2333 - precision: 0.1708 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6970 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.1688 - loss: 0.2322 - precision: 0.1688 - recall: 1.0000 - val_accuracy: 0.1508 - val_loss: 0.6972 - val_precision: 0.1508 - val_recall: 1.0000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.1753 - loss: 0.6951 - precision: 0.1727 - recall: 1.0000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "weighting_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(shape=(256, 256, 3)),\n",
    "    keras.layers.Conv2D(16, (7, 7), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "    keras.layers.Dropout(0.6),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "weighting_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall'],\n",
    ")\n",
    "\n",
    "weighting_history = weighting_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=validation_dataset,\n",
    "    class_weight={0: 0.2, 1: 1}\n",
    ")\n",
    "\n",
    "weighting_results = weighting_model.evaluate(test)\n",
    "weighting_predictions = weighting_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad4a20-cef8-4594-89b9-21f87d9b5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "sns.set_theme(\"notebook\")\n",
    "\n",
    "true_y = np.concatenate([y for _, y in test], axis=0).astype(int)\n",
    "weighted_output = (weighting_predictions > 0.5).astype(int)\n",
    "no_weighting_output = (no_weighting_predictions > 0.5).astype(int)\n",
    "\n",
    "# plot the metrics using seaborn\n",
    "def plot_metrics(history, metrics, title=None):\n",
    "    for metric in metrics:\n",
    "        plt.plot(history.history[metric], label=metric)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(no_weighting_history, ['accuracy', 'precision', 'recall'], title=\"No Weighting Model Metrics\")\n",
    "plot_metrics(weighting_history, ['accuracy', 'precision', 'recall'], title=\"Weighting Model Metrics\")\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, title=None, cmap=plt.cm.Blues):\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', cmap=cmap, xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Class', fontsize=10)\n",
    "    plt.ylabel('Actual Class', fontsize=10)\n",
    "    plt.title(title, fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(true_y, weighted_output, ['normal', 'tuberculosis'], title='Confusion Matrix for Weighted Model')\n",
    "plot_confusion_matrix(true_y, no_weighting_output, ['normal', 'tuberculosis'], title='Confusion Matrix for No Weighting Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86e958-4276-465d-b67a-944f6409e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"./segmentation_data\"\n",
    "image_dir = os.path.join(DATA_DIR, \"images\")\n",
    "mask_dir = os.path.join(DATA_DIR, \"masks\")\n",
    "\n",
    "masks = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n",
    "for mask in masks:\n",
    "    if mask.endswith(\"_mask.png\"):\n",
    "        os.rename(os.path.join(mask_dir, mask), os.path.join(mask_dir, mask.replace(\"_mask\", \"\")))\n",
    "\n",
    "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "for img in images:\n",
    "    if os.path.isfile(os.path.join(mask_dir, img)):\n",
    "        continue\n",
    "    os.remove(os.path.join(image_dir, img))\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "masks = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89601c-ac02-491b-bd9a-0b7908cfd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "masks = [f for f in os.listdir(mask_dir) if os.path.isfile(os.path.join(mask_dir, f))]\n",
    "\n",
    "train_images, val_images, train_masks, val_masks = train_test_split(images, masks, test_size=0.1)\n",
    "\n",
    "if os.path.exists(os.path.join(DATA_DIR, \"train\")):\n",
    "    print(\"Removing existing train dataset...\")\n",
    "    shutil.rmtree(os.path.join(DATA_DIR, \"train\"))\n",
    "\n",
    "if os.path.exists(os.path.join(DATA_DIR, \"val\")):\n",
    "    print(\"Removing existing validation dataset...\")\n",
    "    shutil.rmtree(os.path.join(DATA_DIR, \"val\"))\n",
    "\n",
    "train_image_dir = os.path.join(DATA_DIR, \"train\", \"images\")\n",
    "val_image_dir = os.path.join(DATA_DIR, \"val\", \"images\")\n",
    "train_mask_dir = os.path.join(DATA_DIR, \"train\", \"masks\")\n",
    "val_mask_dir = os.path.join(DATA_DIR, \"val\", \"masks\")\n",
    "\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(val_image_dir, exist_ok=True)\n",
    "os.makedirs(train_mask_dir, exist_ok=True)\n",
    "os.makedirs(val_mask_dir, exist_ok=True)\n",
    "\n",
    "def copy_files(file_list, src_dir, dst_dir):\n",
    "    for file in file_list:\n",
    "        shutil.copy(os.path.join(src_dir, file), os.path.join(dst_dir, file))\n",
    "\n",
    "print(\"Copying train images...\")\n",
    "copy_files(train_images, image_dir, train_image_dir)\n",
    "print(\"Copying validation images...\")\n",
    "copy_files(val_images, image_dir, val_image_dir)\n",
    "print(\"Copying train masks...\")\n",
    "copy_files(train_masks, mask_dir, train_mask_dir)\n",
    "print(\"Copying validation masks...\")\n",
    "copy_files(val_masks, mask_dir, val_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2929ee-ae2d-49db-b5ae-fbf6582f8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "train_masks_dir = os.path.join(DATA_DIR, \"train\", \"masks\")\n",
    "train_images_dir = os.path.join(DATA_DIR, \"train\", \"images\")\n",
    "val_masks_dir = os.path.join(DATA_DIR, \"val\", \"masks\")\n",
    "val_images_dir = os.path.join(DATA_DIR, \"val\", \"images\")\n",
    "\n",
    "train_masks = keras.utils.image_dataset_from_directory(\n",
    "    train_masks_dir,\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256)\n",
    ")\n",
    "\n",
    "train_images = keras.utils.image_dataset_from_directory(\n",
    "    train_images_dir,\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256)\n",
    ")\n",
    "\n",
    "val_masks = keras.utils.image_dataset_from_directory(\n",
    "    val_masks_dir,\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256)\n",
    ")\n",
    "\n",
    "val_images = keras.utils.image_dataset_from_directory(\n",
    "    val_images_dir,\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256)\n",
    ")\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((train_images, train_masks))\n",
    "val_dataset = tf.data.Dataset.zip((val_images, val_masks))\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (x / 255.0, y / 255.0))\n",
    "val_dataset = val_dataset.map(lambda x, y: (x / 255.0, y / 255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41f6ee-be95-4aaf-82f9-009a9cad8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "early_stopper = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "base_model = sm.Unet(\n",
    "    BACKBONE,\n",
    "    encoder_weights='imagenet',\n",
    ")\n",
    "\n",
    "inp = keras.layers.Input(shape=(256, 256, 1))\n",
    "l1 = keras.layers.Conv2D(3, (1, 1))(inp)\n",
    "out = base_model(l1)\n",
    "\n",
    "model = keras.models.Model(inp, out, name=base_model.name)\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=sm.losses.DiceLoss(),\n",
    "    metrics=[sm.metrics.iou_score, sm.metrics.FScore],\n",
    ")\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "    epochs=5,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c26a3f-0340-43db-a8ea-88f12b97fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_images_dir = os.path.join(DATA_DIR, \"test\")\n",
    "test_images = keras.utils.image_dataset_from_directory(\n",
    "    test_images_dir,\n",
    "    label_mode=None,\n",
    "    color_mode='grayscale',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256)\n",
    ")\n",
    "\n",
    "results = model.predict(test_images)\n",
    "for i in range(5):\n",
    "    pred = results[i]\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred > 0.5).astype(np.uint8)\n",
    "    plt.imshow(pred, cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aed11b-195d-48a4-97cb-cb1a60a75873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and validation loss using seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa3f4b-958e-4b82-bc24-276bbc4738b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(test_images_dir)\n",
    "\n",
    "if os.path.exists(os.path.join(DATA_DIR, \"out\")):\n",
    "    print(\"Removing existing output directory...\")\n",
    "    shutil.rmtree(os.path.join(DATA_DIR, \"out\"))\n",
    "\n",
    "os.makedirs(os.path.join(DATA_DIR, \"out\"), exist_ok=True)\n",
    "out_dir = os.path.join(DATA_DIR, \"out\")\n",
    "for pred, fn in zip(results, test_filenames):\n",
    "    pred = np.squeeze(pred)\n",
    "    pred = (pred > 0.5).astype(np.uint8)\n",
    "    plt.imsave(os.path.join(out_dir, fn), pred, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bc7e2-b3e3-4c05-85eb-3c428f7d2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "overlayed_out = os.path.join(DATA_DIR, \"overlayed_out\")\n",
    "\n",
    "os.makedirs(overlayed_out, exist_ok=True)\n",
    "\n",
    "def overlay_mask_on_image(image, mask):\n",
    "    mask = mask > 0.5\n",
    "    overlay_image = np.zeros_like(image)\n",
    "    overlay_image[mask] = image[mask]\n",
    "\n",
    "    return overlay_image\n",
    "\n",
    "for img_name in os.listdir(test_images_dir):\n",
    "    img_path = os.path.join(test_images_dir, img_name)\n",
    "    mask_path = os.path.join(out_dir, img_name)\n",
    "    \n",
    "    original_image = cv2.imread(img_path)\n",
    "    original_image = cv2.resize(original_image, (256, 256))\n",
    "    \n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (256, 256))\n",
    "    mask = mask / 255.0\n",
    "    \n",
    "    overlay_image = overlay_mask_on_image(original_image, mask)\n",
    "\n",
    "    cv2.imwrite(os.path.join(overlayed_out, img_name), overlay_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef3db9-0754-431f-ac50-d88ff6fda560",
   "metadata": {},
   "source": [
    "## Developing the Classification Model\n",
    "\n",
    "### Finding the optimal architecture\n",
    "This will start with a Grid-Search approach, to find the general direction in which to move. Once that is done a human-directed approach will begin. At this stage it is purely about finding the optimal number of layers and neurons per layer.\n",
    "\n",
    "At this stage the focus will be on the convolutional layers, while keeping the densely connected layers stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d932155-6972-48cb-a918-2d32e5f610d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras_tuner\n",
    "\n",
    "# def build_model(hp, deterministic=True):\n",
    "#     if deterministic == True:\n",
    "#         tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "#     conv_kernal_size = hp.Choice(name=\"conv_kernal_size\", values=[7, 16, 32])\n",
    "#     pooling_size = hp.Choice(name=\"pooling_size\", values=[2, 4, 8])\n",
    "\n",
    "#     model = keras.models.Sequential([\n",
    "#         keras.layers.InputLayer(shape=(256, 256, 3)),\n",
    "#         keras.layers.Conv2D(hp.Choice(name=\"conv_filters\", values=[16, 24, 36]), (conv_kernal_size, conv_kernal_size), activation='relu'),\n",
    "#         keras.layers.MaxPooling2D(pool_size=(pooling_size, pooling_size)),\n",
    "#         keras.layers.Flatten(),\n",
    "#         keras.layers.Dense(100, activation='relu'),\n",
    "#         keras.layers.Dense(50, activation='relu'),\n",
    "#         keras.layers.Dense(5, activation='relu'),\n",
    "#         keras.layers.Dropout(0.6),\n",
    "#         keras.layers.Dense(1, activation='sigmoid'),\n",
    "#     ])\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer='rmsprop',\n",
    "#         loss='binary_crossentropy',\n",
    "#         metrics=['accuracy', 'precision', 'recall'],\n",
    "#     )\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a07b2-b565-43c6-b42c-e669d0b4e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = keras.utils.image_dataset_from_directory(\n",
    "#     split_dir + \"/train\",\n",
    "#     labels='inferred',\n",
    "#     label_mode='binary',\n",
    "#     batch_size=32,\n",
    "#     image_size=(256, 256),\n",
    "#     shuffle=True,\n",
    "#     seed=123,\n",
    "#     validation_split=0.1,\n",
    "#     subset='both'\n",
    "# )\n",
    "# train_dataset, validation_dataset = training_data\n",
    "\n",
    "# test = keras.utils.image_dataset_from_directory(\n",
    "#     split_dir + \"/test\",\n",
    "#     labels='inferred',\n",
    "#     label_mode='binary',\n",
    "#     batch_size=32,\n",
    "#     image_size=(256, 256),\n",
    "#     shuffle=True,\n",
    "#     seed=123\n",
    "# )\n",
    "\n",
    "# cb = keras.callbacks.EarlyStopping(\n",
    "#     monitor=\"val_loss\",\n",
    "#     patience=3,\n",
    "#     min_delta=0.01,\n",
    "#     mode=\"auto\",\n",
    "# )\n",
    "\n",
    "# tuner = keras_tuner.GridSearch(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     project_name=\"same_no_layers\"\n",
    "# )\n",
    "\n",
    "# tuner.search(train_dataset, validation_data=validation_dataset, epochs=10, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb768cae-57f1-4596-83c9-6fe78c28f89b",
   "metadata": {},
   "source": [
    "## Increasing Layers\n",
    "\n",
    "Looking at the evaluation performed above there is still a precision of 0 in all cases. However looking at the top results, we can see that more power generally performed better than less power.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next steps I will look at using another existing architecture which was used for [pneumonia binary classification](https://ieeexplore.ieee.org/abstract/document/8985057). TODO: Further explain the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd235f8a-ad9e-4eba-938b-3970a1247a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner\n",
    "\n",
    "def build_model(hp, deterministic=True):\n",
    "    if deterministic == True:\n",
    "        tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(shape=(256, 256, 3)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        # keras.layers.Dropout(0.6),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision', 'recall'],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8782cc-7404-4723-8389-3d0ad4bacad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = keras.utils.image_dataset_from_directory(\n",
    "    split_dir + \"/train\",\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset='both'\n",
    ")\n",
    "train_dataset, validation_dataset = training_data\n",
    "\n",
    "test = keras.utils.image_dataset_from_directory(\n",
    "    split_dir + \"/test\",\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    min_delta=0.01,\n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=[cb],\n",
    "    class_weight={0: 0.25, 1: 1}\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c225a3-6037-47e2-ae98-feb14700faeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
